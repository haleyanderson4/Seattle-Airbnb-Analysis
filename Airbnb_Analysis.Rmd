---
title: "Final Project"
author: "Haley Anderson,  Allison Merrill, Annie Zhu, Karolina Michalewska"
subtitle: "MGSC 310, Fall 2019, Professor Hersh"
output:
  pdf_document: default
  word_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
library(knitr)

# set seed to your own favorite number
set.seed(1818)
options(width=70)

# general rchunk code options
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=TRUE, size = "vsmall")
opts_chunk$set(message = FALSE,
               warning = FALSE,
               cache = TRUE,
               autodep = TRUE,
               cache.comments = FALSE,
               collapse = TRUE,
               fig.width = 5,  
               fig.height = 4,
               fig.align='center')

# install packages
install.packages('wordcloud2')
install.packages('slam')
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator 
install.packages("RColorBrewer") # color palettes
install.packages('randomForest')
install.packages('ranger')
install.packages('randomForestExplainer')
```

## Data Cleaning
```{r}
library('tidyverse')
listings <- read_csv("seattle/listings.csv")

# Remove listings not in Seattle, WA
listings <- listings %>% filter(city=="Seattle",
                                state=="WA")

# Remove listings that have never been stayed at
listings <- listings %>% drop_na(host_acceptance_rate)
listings <- listings %>% filter(host_acceptance_rate!="N/A")

# Data cleaning, removing unecessary variables 
listings_clean <- listings[,c(1,5,9,17,19,20,23,24,
                              25,26,29,30,31,32,33,
                              34,35,36,37,39,40,41,
                              49,50,51,52:85,87:92)]

# Remove listing that has an junk 7 digit zipcode
listings_clean <- listings_clean %>% filter(id != "9448215")  

listings_clean <- listings_clean[,c(1:2,4:40,46,48:57,60:61,63:65)]

# Percentage of NA values
mean(is.na(listings_clean))

listings_clean <- listings_clean %>% mutate(
  price_int = as.numeric(gsub("\\$", "", as.character(listings_clean$price)))
)

# Add factors
df1 <- data.frame(listings_clean$neighbourhood_cleansed)
neighbourhood_cleansed_levels <- unique(df1)
neighbourhood_cleansed_levels <- neighbourhood_cleansed_levels %>% select()
neighbourhood_cleansed_levels <- factor(listings_clean$neighbourhood_cleansed, levels = neighbourhood_cleansed_levels)

df2 <- data.frame(listings_clean$neighbourhood)
neighbourhood_levels <- unique(df2)
neighbourhood_levels <- factor(listings_clean$neighbourhood, levels = neighbourhood_levels)

df3 <- data.frame(listings_clean$zipcode)
zipcode_levels <- unique(df3)
zipcode_factors <- factor(listings_clean$zipcode, levels = zipcode_levels)

df4 <- data.frame(listings_clean$property_type)
property_type_levels <- unique(df4)
property_type_levels
property_type_factor <- factor(listings_clean$property_type, levels = property_type_levels)

df5 <- data.frame(listings_clean$room_type)
room_type_levels <- unique(df5)
room_type_factors <- factor(listings_clean$room_type, levels = room_type_levels)

df6 <- data.frame(listings_clean$bed_type)
bed_type_levels <- unique(df6)
bed_type_factors <- factor(listings_clean$bed_type, levels = bed_type_levels)

# Add factors to data frame
listings_clean <- listings_clean %>% mutate(
  neighbourhood_cleansed_factor = factor(listings_clean$neighbourhood_cleansed, levels = neighbourhood_cleansed_levels),
  zipcode_factor <- factor(listings_clean$neighbourhood, levels = neighbourhood_levels),
  property_type_factor <- factor(listings_clean$property_type, levels = property_type_levels),
  room_type_factor <- factor(listings_clean$room_type, levels = room_type_levels),
  bed_type_factor <- factor(listings_clean$bed_type, levels = bed_type_levels)
)
```

## Summary Statistics
```{r}
# Predicting the nightly price of an Airbnb listing

num_listing <- nrow(listings_clean)
cat("Number of Listings in Seattle: ", num_listing)

house_percent <- (nrow(listings_clean %>% filter(property_type=="House")) /  num_listing)
cat("Percentage of Listings that are a House: ", house_percent)

apartment_percent <- (nrow(listings_clean %>% filter(property_type=="Apartment")) /  num_listing)
cat("Percentage of Listings that are an Apartment: ", apartment_percent)

print(house_percent + apartment_percent)

other_property_listings <- listings_clean %>% filter(property_type!="House", 
                                                     property_type!="Apartment")
#Some of the other property types are:
head(other_property_listings$property_type)

full_house_percent <- (nrow(listings_clean %>% filter(room_type=="Entire home/apt")) / num_listing)
cat("Percentage of Listings that are the Full House / Apartment: ", full_house_percent)

priv_room_percent <- (nrow(listings_clean %>% filter(room_type=="Private room")) / num_listing)
cat("Percentage of Listings that are a Private Room: ", priv_room_percent)

share_room_percent <- (nrow(listings_clean %>% filter(room_type=="Shared room")) / num_listing)
cat("Percentage of Listings that are a Shared Room: ", share_room_percent)

print(full_house_percent + priv_room_percent + share_room_percent)

avg_nightly_price <- mean(listings_clean$price_int, na.rm = TRUE)
median_nightly_price <- median(listings_clean$price_int, na.rm = TRUE)
cat("Average Nightly Price: ", avg_nightly_price, " ||  Median Nightly Price: ", median_nightly_price)

std_dev_nightly_price <- sd(listings_clean$price_int, na.rm = TRUE)
cat("Standard Deviation: ", std_dev_nightly_price)

max_nightly_price <- max(listings_clean$price_int, na.rm = TRUE)
min_nightly_price <- min(listings_clean$price_int, na.rm = TRUE)
cat("Minimum Nightly Price: ", min_nightly_price, " ||  Maximum Nightly Price: ", max_nightly_price)

avg_num_reviews <- mean(listings_clean$number_of_reviews, na.rm = TRUE)
avg_rating <- mean(listings_clean$review_scores_rating, na.rm = TRUE)
cat("Average number of Reviews: ", avg_num_reviews, " ||  Average Rating out of 100: ", avg_rating)

std_dev_reviews <- sd(listings_clean$number_of_reviews, na.rm = TRUE)
std_dev_ratings <- sd(listings_clean$review_scores_rating, na.rm = TRUE)
cat("Number Reviews Standard Deviation: ", std_dev_reviews, " ||  Rating Standard Deviation: ", std_dev_ratings)
```

## Plots
```{r}
library(ggplot2)

# scatter plot of accommodates by price 
ggplot(listings_clean) + aes(x = accommodates , y = price, color = property_type) + geom_point() + 
  theme( axis.text.y = element_blank()) + ylab("price, max = $1000")
 
# room type and accommodates
ggplot(listings_clean) + aes(x = room_type, y = accommodates) + geom_point()

# Correlation matrix
cormat <- cor(listings_clean %>% select_if(is.numeric) %>% drop_na())
corrplot::corrplot(cormat)

# neighborhood bar chart
library(ggplot2)
ggplot(data = listings_clean, aes(x = neighbourhood_cleansed)) + geom_bar(fill = "blue") + coord_flip()

# Gold is Apartment, Blue is House. First 2 are Entire Home, middle 2 are private room, final 2 are shared room
boxplot(price_int ~ property_type + room_type, 
        data = listings_clean %>% filter(price_int < 600 & (property_type=="House" | property_type=="Apartment")), 
        notch=TRUE,
        col=(c("gold","blue")),
        names=c("A & EH", "H & EH", "A & PR",
                "H & PR", "A & SR", "H & SR"),
        at = c(1,2, 4,5, 7,8),
        main="Nightly Price of Airbnbs in Seattle", 
        ylab="Nightly Price",
        xlab="A - Apartment, H - House, EH - Entire House, PR - Private Room, SR - Shared Room"
        )
        
# Proportion of Room Type In Each Zipcode
ggplot(listings_clean) + geom_histogram(aes(zipcode, fill = room_type), stat = "count",alpha = 0.85, position = 'fill') + 
  theme_minimal(base_size=13) + xlab("") + ylab("")  + 
  ggtitle("The Proportion of Room Type in Each Area")
```

## Train / Test Split
```{r}
train_idx <- sample(1:nrow(listings_clean),
                    size = .75 * nrow(listings_clean))

list_short <- listings_clean %>% filter(-c("square_feet", "weekly_price", "monthly_price"))

listings_train <- listings_clean %>% slice(train_idx)
listings_test <- listings_clean %>% slice(-train_idx)
```

## Model 1: Word Cloud
```{r}
# This model is a word graph showing the most commonly used words in listing names
# This method was inspired by http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library('wordcloud2')
wordcloud2(data=listings_clean$name, size=1.6)

docs <- Corpus(VectorSource(listings_clean$name))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)

wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
        col ="lightblue", main ="Most frequent words",
        ylab = "Word frequencies")
```

## Model 2: Lasso Model
```{r}
# Model number one is a lasso model which will help us determine which variables are the most important
library(glmnet)
library(glmnetUtils)

lasso_mod <- cv.glmnet(price_int ~ host_response_time + host_is_superhost + host_total_listings_count +
                         host_has_profile_pic + neighbourhood + neighbourhood_cleansed + 
                         property_type + room_type + accommodates + bedrooms + beds + 
                         cancellation_policy + reviews_per_month,
                       data = listings_train,
                       alpha = 1,
                       nfolds = 10) 
summary(lasso_mod)
plot(lasso_mod)

library('coefplot')
coef(lasso_mod, s = "lambda.min")
coef(lasso_mod, s = "lambda.1se")
```

## Model 3: Random Forest
```{r}
library('randomForest')
library('ranger')

rf_mods <- list()
oob_err <- NULL

for(i in 1:9) {
  #fit RF model and vary mtry everytime
  rf_mod <- randomForest(chd ~.,
                         data = SA_train,
                         type = classification,
                         mtry = i,
                         ntree = 1000)
  rf_mods[[i]] <- rf_mod
  oob_err[i] <- rf_mod$err.rate[1000]
}

results_DF <- data.frame(
  mtry = 1:9,
  oob_err
)

ggplot(results_DF, aes(x= mtry, y = oob_err)) + geom_point()

mtry_optimal <- oob_err[] # add best

rt_fit <- randomForest(price_int ~ .,
                       data = listings_train,
                       na.action = na.omit,
                       mtry = mtry_optimal,
                       ntree = 10000,
                       importance = TRUE,
                       localImp = TRUE) 

plot(rt_fit, ylim = c(0,1))

library('randomForestExplainer')
explain_forest(rt_fit,
               interactions = TRUE, 
               data = listings_train)
```
