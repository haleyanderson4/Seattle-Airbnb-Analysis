---
title: "Final Project"
author: "Haley Anderson,  Allison Merrill, Annie Zhu, Karolina Michalewska"
subtitle: "MGSC 310, Fall 2019, Professor Hersh"
output:
  pdf_document: default
  word_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
library(knitr)

# set seed to your own favorite number
set.seed(1818)
options(width=70)

# general rchunk code options
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=TRUE, size = "vsmall")
opts_chunk$set(message = FALSE,
               warning = FALSE,
               cache = TRUE,
               autodep = TRUE,
               cache.comments = FALSE,
               collapse = TRUE,
               fig.width = 5,  
               fig.height = 4,
               fig.align='center')
               
# install packages
install.packages('wordcloud2')
install.packages('slam')
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator 
install.packages("RColorBrewer") # color palettes
```

## Data Cleaning
```{r}
library('tidyverse')
listings <- read_csv("seattle/listings.csv")

# Remove listinings not in Seattle, WA
listings <- listings %>% filter(city=="Seattle",
                                state=="WA")
                                
# Remove listings that have never been stayed at
listings <- listings %>% drop_na(host_acceptance_rate)
listings <- listings %>% filter(host_acceptance_rate!="N/A")

# Data cleaning, removing unecessary variables 
listings_clean <- listings[,c(1,5,9,17,19,20,23,24,
                              25,26,29,30,31,32,33,
                              34,35,36,37,39,40,41,
                              49,50,51,52:85,87:92)]
                              
listings_clean <- listings_clean %>% filter(id != "9448215")                            
                              
listings_clean <- listings_clean[,c(1:40,46,48:57,60:61,63:65)]

listings_clean <- listings_clean %>% mutate(
  price_int = as.numeric(gsub("\\$", "", as.character(listings_clean$price)))
  )

# Add factors
df1 <- data.frame(listings$neighbourhood_cleansed)
nieghborhood_cleansed_levels <- unique(df1)
nieghborhood_cleansed_factors <- factor(listings$nieghborhood_cleansed, levels = nieghborhood_cleansed_levels)

df2 <- data.frame(listings$neighbourhood)
nieghborhood_levels <- unique(df2)
nieghborhood_factors <- factor(listings$nieghborhood, levels = nieghborhood_levels)

df3 <- data.frame(listings$zipcode)
zipcode_levels <- unique(df3)
zipcode_factors <- factor(listings$zipcode, levels = zipcode_levels)

df4 <- data.frame(listings$property_type)
property_type_levels <- unique(df4)
property_type_levels
property_type_factor <- factor(listings$property_type, levels = property_type_levels)

df5 <- data.frame(listings$room_type)
room_type_levels <- unique(df5)
room_type_factors <- factor(listings$room_type, levels = room_type_levels)
# add factor levels here
```

## Summary Statistics
```{r}
# Predicting the nightly price of an Airbnb listing

num_listing <- nrow(listings_clean)
cat("Number of Listings in Seattle: ", num_listing)

house_percent <- (nrow(listings_clean %>% filter(property_type=="House")) /  num_listing)
cat("Percentage of Listings that are a House: ", house_percent)

apartment_percent <- (nrow(listings_clean %>% filter(property_type=="Apartment")) /  num_listing)
cat("Percentage of Listings that are an Apartment: ", apartment_percent)

print(house_percent + apartment_percent)

other_property_listings <- listings_clean %>% filter(property_type!="House", 
                                                     property_type!="Apartment")
#Some of the other property types are:
head(other_property_listings$property_type)

full_house_percent <- (nrow(listings_clean %>% filter(room_type=="Entire home/apt")) / num_listing)
cat("Percentage of Listings that are the Full House / Apartment: ", full_house_percent)

priv_room_percent <- (nrow(listings_clean %>% filter(room_type=="Private room")) / num_listing)
cat("Percentage of Listings that are a Private Room: ", priv_room_percent)

share_room_percent <- (nrow(listings_clean %>% filter(room_type=="Shared room")) / num_listing)
cat("Percentage of Listings that are a Shared Room: ", share_room_percent)

print(full_house_percent + priv_room_percent + share_room_percent)

avg_nightly_price <- mean(listings_clean$price_int, na.rm = TRUE)
median_nightly_price <- median(listings_clean$price_int, na.rm = TRUE)
cat("Average Nightly Price: ", avg_nightly_price, " ||  Median Nightly Price: ", median_nightly_price)

std_dev_nightly_price <- sd(listings_clean$price_int, na.rm = TRUE)
cat("Standard Deviation: ", std_dev_nightly_price)

max_nightly_price <- max(listings_clean$price_int, na.rm = TRUE)
min_nightly_price <- min(listings_clean$price_int, na.rm = TRUE)
cat("Minimum Nightly Price: ", min_nightly_price, " ||  Maximum Nightly Price: ", max_nightly_price)

avg_num_reviews <- mean(listings_clean$number_of_reviews, na.rm = TRUE)
avg_rating <- mean(listings_clean$review_scores_rating, na.rm = TRUE)
cat("Average number of Reviews: ", avg_num_reviews, " ||  Average Rating out of 100: ", avg_rating)

std_dev_reviews <- sd(listings_clean$number_of_reviews, na.rm = TRUE)
std_dev_ratings <- sd(listings_clean$review_scores_rating, na.rm = TRUE)
cat("Number Reviews Standard Deviation: ", std_dev_reviews, " ||  Rating Standard Deviation: ", std_dev_ratings)
```

## Plots
```{r}
# Gold is Apartment, Blue is House. First 2 are Entire Home, middle 2 are private room, final 2 are shared room
boxplot(price_int ~ property_type + room_type, 
        data = listings_clean %>% filter(price_int < 600 & (property_type=="House" | property_type=="Apartment")), 
        notch=TRUE,
        col=(c("gold","blue")),
        names=c("A & EH", "H & EH", "A & PR",
                "H & PR", "A & SR", "H & SR"),
        at = c(1,2, 4,5, 7,8),
        main="Nightly Price of Airbnbs in Seattle", 
        ylab="Nightly Price",
        xlab="A - Apartment, H - House, EH - Entire House, PR - Private Room, SR - Shared Room"
        )
```

## Model 1: Lasso Model
```{r}
# Model number one is a lasso model which will help us determine which variables are the most important
library(glmnet)
library(glmnetUtils)

lasso_mod <- cv.glmnet(price_int ~ host_response_time + host_is_superhost + host_total_listings_count +
                         host_has_profile_pic + neighbourhood + neighbourhood_cleansed + 
                         property_type + room_type + accommodates + bedrooms + beds + 
                         cancellation_policy + reviews_per_month,
                       data = listings_clean,
                       alpha = 1,
                       nfolds = 10) 
summary(lasso_mod)
plot(lasso_mod)

library('coefplot')
coef(lasso_mod, s = "lambda.min")
coef(lasso_mod, s = "lambda.1se")
```

## Model 2: Word Cloud
```{r}
# This model is a word graph showing the most commonly used words in listing names
# This method was inspired by http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library('wordcloud2')
wordcloud2(data=listings_clean$name, size=1.6)

docs <- Corpus(VectorSource(listings_clean$name))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)

wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
        col ="lightblue", main ="Most frequent words",
        ylab = "Word frequencies")
```
